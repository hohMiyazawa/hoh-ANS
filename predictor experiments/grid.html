<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8">
		<title>Predictor experiments</title>
		<style>
.canvasContainer{
	display: inline-block;
	padding: 5px;
	margin: 5px;
	border: solid;
	border-width: 1px;
	border-radius: 3px;
	max-width: 40%;
}
canvas{
	max-width: 100%;
	max-height: 600px;
	min-width: 16px;
}
body{
	background: rgb(200,200,200);
	padding: 20px;
}
		</style>
		<script src="colourspace.js"></script>
	</head>
	<body>
		<div class="canvasContainer">
			<h2>Original</h2>
			<canvas id="preview" width="0" height="0"></canvas>
		</div>
		<div class="canvasContainer">
			<h2>Current layer</h2>
			<canvas id="render" width="0" height="0"></canvas>
		</div>
		<div class="canvasContainer">
			<h2>Cost estimation</h2>
			<p id="estimate"></p>
			<canvas id="render_cost" width="0" height="0"></canvas>
			<canvas id="predictor_map" width="0" height="0"></canvas>
			<canvas id="entropy_map" width="0" height="0"></canvas>
		</div>
		<hr>
		<h3>Upload</h3>
		<input type="file" id="imageInput"><br>
		<button id="encodeButton">Load</button>
		<h4>Predictors:</h4>
		<div id="parameters"></div>
		<button onclick="tune()">Tune</button>
		<pre id="encodeStats"></pre>
		<script>
let saveByteArray = (function(){
	let a = document.createElement("a");
	document.body.appendChild(a);
	a.style = "display: none";
	return function(data,name){
		let blob = new Blob(data, {type: "octet/stream"});
		let url = window.URL.createObjectURL(blob);
		a.href = url;
		a.download = name;
		a.click();
		window.URL.revokeObjectURL(url)
	}
}())

function readFileAsArrayBuffer(file, success, error) {
	let fr = new FileReader();
	fr.addEventListener('error', error, false);
	if(fr.readAsBinaryString){
		fr.addEventListener('load', function(){
			var string = this.resultString != null ? this.resultString : this.result;
			var result = new Uint8Array(string.length);
			for(var i = 0; i < string.length; i++){
				result[i] = string.charCodeAt(i)
			}
			success(result.buffer)
		}, false);
		return fr.readAsBinaryString(file);
	}
	else {
		fr.addEventListener('load', function(){
			success(this.result)
		}, false);
		return fr.readAsArrayBuffer(file)
	}
}

function drawToCanvas(imageData,id){
	let canvas = document.getElementById(id);
	if(!imageData.imageData){
		return
	}
	canvas.width = imageData.width;
	canvas.height = imageData.height;
	let ctx = canvas.getContext("2d");
	let image = new ImageData(new Uint8ClampedArray(imageData.imageData),imageData.width);
	ctx.putImageData(image,0,0);
}

function drawGreyscale(imageData,width,height){
	let opacity = new Array(imageData.length).fill(0).map(_ => new Array(imageData[0].length).fill(255));
	let image = new ImageData(new Uint8ClampedArray(multiplexChannels([imageData,imageData,imageData,opacity])),width);
	let canvas = document.getElementById("render");
	canvas.width = width;
	canvas.height = height;
	let ctx = canvas.getContext("2d");
	ctx.putImageData(image,0,0);
}

function drawCost(imageData,width,height){
	let opacity = new Array(imageData.length).fill(0).map(_ => new Array(imageData[0].length).fill(255));
	let image = new ImageData(new Uint8ClampedArray(multiplexChannels([imageData,imageData,imageData,opacity])),width);
	let canvas = document.getElementById("render_cost");
	canvas.width = width;
	canvas.height = height;
	let ctx = canvas.getContext("2d");
	ctx.putImageData(image,0,0);
}

function drawPredictorMap(imageData,width,height){
	let image = new ImageData(new Uint8ClampedArray(imageData.map(val => [val,val,val,255]).flat()),width);
	let canvas = document.getElementById("predictor_map");
	canvas.width = width;
	canvas.height = height;
	let ctx = canvas.getContext("2d");
	ctx.putImageData(image,0,0);
}

function drawEntropyMap(imageData,width,height){
	let image = new ImageData(new Uint8ClampedArray(imageData.map(val => [val,val,val,255]).flat()),width);
	let canvas = document.getElementById("entropy_map");
	canvas.width = width;
	canvas.height = height;
	let ctx = canvas.getContext("2d");
	ctx.putImageData(image,0,0);
}

let green_channel;

let predictors = [
	{
		name: "FFV1",
		predict: function(L,TL,T,TR){return [T,L,T + L - TL].sort((a,b) => a - b)[1]}
	},
	{
		name: "LOCO",
		predict: function(L,TL,T,TR){
			if(TL >= Math.max(L,T)){
				return Math.min(L,T)
			}
			else if(TL <= Math.min(L,T)){
				return Math.max(L,T)
			}
			else{
				return L + T - TL
			}
		}
	},

	{
		name: "NULL",
		predict: function(L,TL,T,TR){return 0}
	},
	{
		name: "left",
		predict: function(L,TL,T,TR){return L}
	},

	{
		name: "top",
		predict: function(L,TL,T,TR){return T}
	},
	{
		name: "top-left",
		predict: function(L,TL,T,TR){return TL}
	},
	{
		name: "top-right",
		predict: function(L,TL,T,TR){return TR}
	},

	{
		name: "median",
		predict: function(L,TL,T,TR){return [T,L,TL].sort((a,b) => a - b)[1]}
	},
	{
		name: "avg L-T",
		predict: function(L,TL,T,TR){return Math.floor((T + L)/2)}
	},

	{
		name: "avg L-TL",
		predict: function(L,TL,T,TR){return Math.floor((L + TL)/2)}
	},
	{
		name: "avg TL-T",
		predict: function(L,TL,T,TR){return Math.floor((T + TL)/2)}
	},
	{
		name: "avg T-TR",
		predict: function(L,TL,T,TR){return Math.floor((T + TR)/2)}
	},
	{
		name: "avg3 L-L-TL",
		predict: function(L,TL,T,TR){return Math.floor((L + L + TL)/3)}
	},
	{
		name: "avg3 L-TL-TL",
		predict: function(L,TL,T,TR){return Math.floor((L + TL + TL)/3)}
	},
	{
		name: "avg3 TL-TL-T",
		predict: function(L,TL,T,TR){return Math.floor((TL + TL + T)/3)}
	},
	{
		name: "avg3 TL-T-T",
		predict: function(L,TL,T,TR){return Math.floor((TL + T + T)/3)}
	},
	{
		name: "avg3 T-T-TR",
		predict: function(L,TL,T,TR){return Math.floor((T + T + TR)/3)}
	},
	{
		name: "avg3 T-TR-TR",
		predict: function(L,TL,T,TR){return Math.floor((T + TR + TR)/3)}
	},
	{
		name: "avg4",
		predict: function(L,TL,T,TR){return Math.floor((L + TL + T + TR)/4)}
	},
	{
		name: "avg4 L-TL-TL-T",
		predict: function(L,TL,T,TR){return Math.floor((L + TL + TL + T)/4)}
	},
	{
		name: "paeth",
		predict: function(L,TL,T,TR){
			let p = T + L - TL;
			let Tp = Math.abs(T - p);
			let Lp = Math.abs(L - p);
			let TLp = Math.abs(TL - p);
			if(Tp < Lp){
				if(Tp < TLp){
					return T;
				}
				return TL;
			}
			else{
				if(Lp < TLp){
					return L;
				}
				return TL;
			}
		}
	},
	{
		name: "semi-paeth",
		predict: function(L,TL,T,TR){
			let p = T + L - TL;
			let Tp = Math.abs(T - p);
			let Lp = Math.abs(L - p);
			if(Tp < Lp){
				return T
			}
			else{
				return L
			}
		}
	},
	{
		name: "weird",
		predict: function(L,TL,T,TR){return Math.floor((L + TR + 2*T)/4)}
	},
	{
		name: "CAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(T + L - TL,0),255)}
	},

	{
		name: "CAH",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.floor((L+T)/2 + ((L+T)/2 - TL)/2),0),255)}
	},

	{
		name: "SCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((3*T + 3*L - 2*TL)/4),0),255)}
	},
	{
		name: "SSCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((5*T + 5*L - 2*TL)/8),0),255)}
	},
	{
		name: "TCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((2*T + L - TL)/2),0),255)}
	},
	{
		name: "LCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((T + 2*L - TL)/2),0),255)}
	},
	{
		name: "TTCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((3*T + 2*L - TL)/4),0),255)}
	},
	{
		name: "LLCAF",
		predict: function(L,TL,T,TR){return Math.min(Math.max(Math.round((2*T + 3*L - TL)/4),0),255)}
	}
];
/*
for(let L=0;L<2;L++){
	for(let T=0;T<2;T++){
		for(let TR=0;TR<2;TR++){
			for(let TL=-1;TL<2;TL++){
			let gsum = T + L + TR + TL;
			if(gsum < 1){
				continue
			}
			if([L,TL,T,TR].map(a => a/2).filter(val => Math.ceil(val) !== Math.floor(val)).length === 0){
				continue
			}
			if([L,TL,T,TR].map(a => a/3).filter(val => Math.ceil(val) !== Math.floor(val)).length === 0){
				continue
			}
			if([L,TL,T,TR].map(a => a/4).filter(val => Math.ceil(val) !== Math.floor(val)).length === 0){
				continue
			}
			if([L,TL,T,TR].map(a => a/5).filter(val => Math.ceil(val) !== Math.floor(val)).length === 0){
				continue
			}
predictors.push({
	"name": [L,TL,T,TR].join(","),
	"predict": function(a,b,c,d){return Math.min(Math.max(Math.round((L*a + TL*b + T*c + TR*d)/gsum),0),255)}
})
			}
		}
	}
}*/

/*
[
	[0,0,0,1],
	[0,0,1,0],
	[0,1,1,0],
	[0,1,3,0],
	[1,0,0,0],
	[1,-1,1,0],
	[1,-1,2,0],
	[1,-1,3,0],
	[1,0,3,0],
	[2,-1,0,1],
	[2,-1,0,2],
	[2,-1,0,3],
	[2,-1,1,0],
	[2,-1,1,1],
	[3,-1,0,1],
	[3,-1,1,0]
].forEach(selected => {
	let L = selected[0];
	let TL = selected[1];
	let T = selected[2];
	let TR = selected[3];
	let gsum = L + TL + T + TR;
	predictors.push({
		"name": [L,TL,T,TR].join(","),
		"predict": function(a,b,c,d){return Math.min(Math.max(Math.round((L*a + TL*b + T*c + TR*d)/gsum),0),255)}
	})
})
*/


/*
"102 0,0,1,0"
"287 1,-1,1,0"
"272 1,0,1,0"
"419 1,-1,2,0" (L + 2*T - TL)/2
"417 1,0,2,0"  (L + 2*T)/3
"159 1,-1,2,1"
"175 1,0,2,1"
"188 2,-1,0,1"
"128 2,-1,0,2"
"322 2,-1,1,0" (2*L + T - TL)/2
"147 2,0,1,0"
"338 2,-1,1,1" (2*L + T + TR - TL)/3
"115 2,0,1,1"
"507 2,-1,2,0" (2*L + 2*T - TL)/3
"113 2,-2,2,1"
"332 2,-1,2,1" (2*L + 2*T + TR - TL)/4
"193 2,0,2,1"
*/

/*
"826 3,-1,1,1"
"702 2,-1,1,1"
"587 1,-1,1,0" CAF
"530 3,-1,2,1"
"482 1,0,0,0"  LEFT
"430 2,-1,2,0"
"424 0,0,1,0"  TOP
"391 2,-1,1,0"
"327 3,-1,0,1"
"326 2,-1,2,1"
"308 3,-1,1,2"
"303 3,-1,2,0"
"301 2,-1,3,1"
"280 3,-1,0,2"
"272 1,-1,2,0"
"266 3,-1,3,1"
"256 2,-1,3,0"
"242 3,-1,3,0"
"224 3,0,1,1"
"221 3,0,0,1"
"194 2,0,0,1"
"188 3,-1,1,0"
"187 2,-1,0,1"
"167 2,0,1,1"
"160 1,-1,3,0"
"148 3,-1,2,2"
"133 3,0,0,2"
"127 1,0,1,0"
"120 3,0,2,1"
"118 3,-1,3,2"
"99 2,0,2,1"
"97 3,0,1,0"
"95 3,0,3,1"
"91 3,0,1,2"
"84 2,-1,0,2"
"83 2,0,1,0"
"80 1,0,0,1"
"80 2,-1,2,2"
*/


/*
"1890 3,-1,0,2"
"1698 3,-1,1,1"
"1160 3,-1,0,1"
"813 2,-1,1,1"
"617 3,-1,2,1"
"528 2,-1,0,1"
"469 3,-1,2,0"
"446 3,-1,1,2"
"377 3,0,1,1"
"377 3,0,0,1"
"283 3,-1,0,3"
"275 3,-1,3,1"
"267 3,0,2,1"
"253 2,0,0,1"
"250 2,-1,1,0"
"248 2,-1,0,2"
"238 3,-1,3,0"
"228 3,-1,2,2"
"219 2,0,1,1"
"198 2,-1,2,1"
"191 2,-1,2,0"
"190 2,0,1,0"
"183 3,0,0,2"
"183 3,0,2,0"
"177 1,0,1,0"
"165 3,-1,1,0"
"156 3,0,3,1"
"153 3,0,1,2"
"152 3,0,1,0"
"127 3,-1,3,2"
"123 3,0,2,2"
"120 2,0,2,1"
"116 2,-1,1,2"
"114 3,-1,1,3"
"94 2,-1,3,1"
"94 3,1,1,1"
"85 1,0,0,1"
"82 3,-1,2,3"
"80 2,0,3,0"
*/
let mixers = [
/*
	[0,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,18,19,20,21,22,23,26,27,28,29],
	[2,3],
	[0,5,6,21,27],
	[2,3,4,5],
	[0,5,7,22],
	[29,6]
*/
]

const Stats = {
	average: function(list){
		return list.reduce((a,b) => (a || 0) + (b || 0))/list.length
	},
	median: function(list){
		let temp = [...list].sort((a,b) => a - b);
		return (
			temp[Math.floor((temp.length - 1)/2)]
			+ temp[Math.ceil((temp.length - 1)/2)]
		)/2;
	},
	mode: function(list){
		return [...list].sort(
			(b,a) => list.filter(
				e => e === a
			).length - list.filter(
				e => e === b
			).length
		)[0];
	}
}

function laplace(para){
	let freqs = new Array(256).fill(0);
	return freqs.map((_,index) => Math.pow(2,-Math.min(index,256 - index)/para))
}

function freqs(list){
	let freqs = new Array(256).fill(0);
	list.forEach(value => freqs[value]++)
	return freqs
}
function estimateEntropy(list){
	const freqs = {};
	list.forEach(symbol => {
		freqs[symbol] = (freqs[symbol] || 0) + 1
	})
	let entropy = 0;
	Object.keys(freqs).map(key => freqs[key]).forEach(key => {
		entropy += - key * Math.log2(key/list.length)
	})
	return entropy
}
function estimateEntropy_freqs(freqs){
	let total = freqs.reduce((acc,val) => acc + val,0);
	return freqs.filter(val => val).reduce((acc,val) => acc - Math.log2(val/total) * val,0)
}
function local_estimateEntropy_inclusive(freqs,local_symbols){
	let newFreqs = freqs.map(a => a);
	local_symbols.forEach(symbol => newFreqs[symbol]++);
	let total = newFreqs.reduce((acc,val) => acc + val,0);
	return local_symbols.reduce((acc,val) => acc - Math.log2(newFreqs[val]/total),0)
}
function local_estimateEntropy_exclusive(freqs,local_symbols){//be aware of null symbols!
	let total = freqs.reduce((acc,val) => acc + val,0);
	return local_symbols.reduce((acc,val) => acc - Math.log2(freqs[val]/total),0)
}
function estimate_table_size(freqs){//bytes
	let largest = Math.max(...freqs);
	let bits = Math.ceil(Math.log2(largest));
	let best = Math.ceil(bits*freqs.length/8) + 1;
	for(let lower=bits-1;bits - lower <=8;lower--){
		let within = freqs.filter(a => a <= Math.pow(2,lower) - 1).length;
		let maybe_better = Math.ceil((lower*within + bits*(freqs.length - within))/8) + 3;
		if(maybe_better < best){
			best = maybe_better
		}
	}
	return best
}
function codeFromValue(value){
	if(value <= 4){
		return [value - 1,0]
	}
	if(value <= 6){
		return [4,1]
	}
	if(value <= 8){
		return [5,1]
	}
	if(value <= 12){
		return [6,2]
	}
	if(value <= 16){
		return [7,2]
	}
	if(value <= 24){
		return [8,3]
	}
	if(value <= 32){
		return [9,3]
	}
	if(value <= 48){
		return [10,4]
	}
	if(value <= 64){
		return [11,4]
	}
	if(value <= 96){
		return [12,5]
	}
	if(value <= 128){
		return [13,5]
	}
	if(value <= 192){
		return [14,6]
	}
	if(value <= 256){
		return [15,6]
	}
	if(value <= 384){
		return [16,7]
	}
	if(value <= 512){
		return [17,7]
	}
	if(value <= 768){
		return [18,8]
	}
	if(value <= 1024){
		return [19,8]
	}
	if(value <= 1536){
		return [20,9]
	}
	if(value <= 2048){
		return [21,9]
	}
	if(value <= 3072){
		return [22,10]
	}
	if(value <= 4096){
		return [23,10]
	}
	if(value <= 4096 + 2048){
		return [24,11]
	}
	if(value <= 8192){
		return [25,11]
	}
	if(value <= 8192 * 1.5){
		return [26,12]
	}
	if(value <= 8192 * 2){
		return [27,12]
	}
	if(value <= 8192 * 3){
		return [28,13]
	}
	if(value <= 8192 * 4){
		return [29,13]
	}
	if(value <= 8192 * 6){
		return [30,14]
	}
	if(value <= 8192 * 8){
		return [31,14]
	}
	if(value <= 8192 * 12){
		return [32,15]
	}
	if(value <= 8192 * 16){
		return [33,15]
	}
	if(value <= 8192 * 24){
		return [34,16]
	}
	if(value <= 8192 * 32){
		return [35,16]
	}
}
function estimateEntropy_prefixcode(list){
	let pairs = list.map(val => codeFromValue(val));
	return estimateEntropy(pairs.map(pair => pair[0])) + pairs.map(pair => pair[1]).reduce((acc,val) => acc + val,0)
}

const BOUND = 8;

let global_coded;

function tune(contexts,lzrangeormixfree,minmatch,maxmatch,minentropy){
	let image_width = green_channel[0].length;
	let image_height = green_channel.length;
	let tile_width = Math.ceil(image_width/BOUND);
	let tile_height = Math.ceil(image_height/BOUND);
	let tile_number = tile_width * tile_height;

	let tile_predictors = new Array(tile_number).fill(0);
	let tile_entropy = new Array(tile_number).fill(0);
	let predictBlock = function(predictor,tile_index){
		let collected = [];
		for(let y=0;y<BOUND;y++){
			let pixel_y = Math.floor(tile_index / tile_width) * BOUND + y;
			if(pixel_y >= image_height){
				continue
			}
			for(let x=0;x<BOUND;x++){
				let pixel_x = (tile_index % tile_width) * BOUND + x;
				if(pixel_x >= image_width){
					continue
				}
				let VAL = green_channel[
					pixel_y
				][
					pixel_x
				];
				let L;
				let TL;
				let T;
				let TR;
				if(pixel_y === 0){
					TL = 128;
					T = 128;
					TR = 128;
					if(pixel_x === 0){
						L = 128
					}
					else{
						L = green_channel[pixel_y][pixel_x - 1]
					}
				}
				else{
					T = green_channel[pixel_y - 1][pixel_x];
					if(pixel_x === 0){
						L = 128;
						TR = green_channel[pixel_y - 1][pixel_x + 1];
						TL = 128;
					}
					else if(pixel_x === image_width - 1){
						L = green_channel[pixel_y][pixel_x - 1];
						TR = 128;
						TL = green_channel[pixel_y - 1][pixel_x - 1];
					}
					else{
						L = green_channel[pixel_y][pixel_x - 1];
						TR = green_channel[pixel_y - 1][pixel_x + 1];
						TL = green_channel[pixel_y - 1][pixel_x - 1];
					}
				}
				collected.push((VAL - predictors[predictor].predict(L,TL,T,TR) + 256) % 256)
			}
		}
		return collected
	}
	let predictBlockMix = function(tile_index){
		if(//dissallow bordre blocks to simplify tests
			Math.floor(tile_index / tile_width) * BOUND < 2
			|| (tile_index % tile_width) * BOUND < 2
			|| Math.floor(tile_index / tile_width) * BOUND + (BOUND + 2) >= image_height
			|| (tile_index % tile_width) * BOUND + (BOUND + 2) >= image_width
		){
			return predictBlock(0,tile_index)
		}
		let collected = [];
		for(let y=0;y<BOUND;y++){
			let pixel_y = Math.floor(tile_index / tile_width) * BOUND + y;
			for(let x=0;x<BOUND;x++){
				let pixel_x = (tile_index % tile_width) * BOUND + x;
				let VAL1= green_channel[pixel_y - 1][pixel_x];
				let L1  = green_channel[pixel_y - 1][pixel_x - 1];
				let TL1 = green_channel[pixel_y - 2][pixel_x - 1];
				let T1  = green_channel[pixel_y - 2][pixel_x];
				let TR1 = green_channel[pixel_y - 2][pixel_x + 1];

				let errors1 = predictors.map(pred => 1/(1 + Math.pow(VAL1 - pred.predict(L1,TL1,T1,TR1),2)));

				let VAL2= green_channel[pixel_y][pixel_x - 1];
				let L2  = green_channel[pixel_y][pixel_x - 2];
				let TL2 = green_channel[pixel_y - 1][pixel_x - 2];
				let T2  = green_channel[pixel_y - 1][pixel_x - 1];
				let TR2 = green_channel[pixel_y - 1][pixel_x];

				let errors2 = predictors.map(pred => 1/(1 + Math.pow(VAL2 - pred.predict(L2,TL2,T2,TR2),2)));

				let VAL = green_channel[
					pixel_y
				][
					pixel_x
				];
				let L  = green_channel[pixel_y][pixel_x - 1];
				let TL = green_channel[pixel_y - 1][pixel_x - 1];
				let T  = green_channel[pixel_y - 1][pixel_x];
				let TR = green_channel[pixel_y - 1][pixel_x + 1];

				let weightSum = 0;
				let predSum = 0;

				predictors.forEach((predictor,pIndex) => {
					let entryWeight = errors1[pIndex] * errors2[pIndex];
					weightSum += entryWeight;
					let ppp = predictors[pIndex].predict(L,TL,T,TR);
					predSum += entryWeight * ppp;
				});
				collected.push((VAL - Math.round(predSum/weightSum) + 256) % 256)
			}
		}
		return collected
	}
	let predictBlockMix2 = function(tile_index,mixerIndex){
		if(//dissallow bordre blocks to simplify tests
			Math.floor(tile_index / tile_width) * BOUND < 2
			|| (tile_index % tile_width) * BOUND < 2
			|| Math.floor(tile_index / tile_width) * BOUND + (BOUND + 2) >= image_height
			|| (tile_index % tile_width) * BOUND + (BOUND + 2) >= image_width
		){
			return predictBlock(0,tile_index)
		}
		let collected = [];
		for(let y=0;y<BOUND;y++){
			let pixel_y = Math.floor(tile_index / tile_width) * BOUND + y;
			for(let x=0;x<BOUND;x++){
				let pixel_x = (tile_index % tile_width) * BOUND + x;
				let VAL1= green_channel[pixel_y - 1][pixel_x];
				let L1  = green_channel[pixel_y - 1][pixel_x - 1];
				let TL1 = green_channel[pixel_y - 2][pixel_x - 1];
				let T1  = green_channel[pixel_y - 2][pixel_x];
				let TR1 = green_channel[pixel_y - 2][pixel_x + 1];

				let errors1 = mixers[mixerIndex].map(pred => 1/(1 + Math.pow(VAL1 - predictors[pred].predict(L1,TL1,T1,TR1),2)));

				let VAL2= green_channel[pixel_y][pixel_x - 1];
				let L2  = green_channel[pixel_y][pixel_x - 2];
				let TL2 = green_channel[pixel_y - 1][pixel_x - 2];
				let T2  = green_channel[pixel_y - 1][pixel_x - 1];
				let TR2 = green_channel[pixel_y - 1][pixel_x];

				let errors2 = mixers[mixerIndex].map(pred => 1/(1 + Math.pow(VAL2 - predictors[pred].predict(L2,TL2,T2,TR2),2)));

				/*let errorsP = mixers[mixerIndex].map(pred => 1/(1 + (
					Math.pow(VAL2 - predictors[pred].predict(L2,TL2,T2,TR2),2)
					+ Math.pow(VAL1 - predictors[pred].predict(L1,TL1,T1,TR1),2)
				)/2 ));*/


				let VAL = green_channel[
					pixel_y
				][
					pixel_x
				];
				let L  = green_channel[pixel_y][pixel_x - 1];
				let TL = green_channel[pixel_y - 1][pixel_x - 1];
				let T  = green_channel[pixel_y - 1][pixel_x];
				let TR = green_channel[pixel_y - 1][pixel_x + 1];

				let weightSum = 0;
				let predSum = 0;

				mixers[mixerIndex].forEach((predictor,pIndex) => {
					//let entryWeight = errorsP[pIndex];
					let entryWeight = errors1[pIndex] * errors2[pIndex];
					weightSum += entryWeight;
					let ppp = predictors[predictor].predict(L,TL,T,TR);
					predSum += entryWeight * ppp;
				});
				collected.push((VAL - Math.round(predSum/weightSum) + 256) % 256)
			}
		}
		return collected
	}

	let coded = tile_predictors.map((predictor,index) => predictBlock(predictor,index));

	let entropy = estimateEntropy(coded.flat());
	console.log(entropy/8,"initial");
	let global_table = freqs(coded.flat());
	if(contexts === "lz"){
		let coded2;
		for(let i=0;i<2;i++){
			let new_tiles = [];
			tile_predictors.forEach((tile,index) => {
				let predictor_results = predictors.map((predictor,pIndex) => 
					local_estimateEntropy_inclusive(
						global_table,
						predictBlock(pIndex,index)
					)
				);
				predictor_results.push(
					local_estimateEntropy_inclusive(
						global_table,
						predictBlockMix(index)
					)
				)
				new_tiles.push(predictor_results.indexOf(Math.min(...predictor_results)))
			});
			coded2 = new_tiles.map((predictor,index) => (predictor === predictors.length ? predictBlockMix(index) : predictBlock(predictor,index)));
			let entropy2 = estimateEntropy(coded2.flat());
			if(entropy2 > entropy){
				break
			}
			entropy = entropy2;
			tile_predictors = new_tiles;
			global_table = freqs(coded2.flat());
			console.log(entropy/8,"secondary");
		};
		let entropyData = new Array(image_height).fill(0).map(_ => new Array(image_width).fill(0));
		coded2.forEach((group,tile_index) => {
			let gIndex = 0;
			for(let y=0;y<BOUND;y++){
				let pixel_y = Math.floor(tile_index / tile_width) * BOUND + y;
				if(pixel_y >= image_height){
					continue
				}
				for(let x=0;x<BOUND;x++){
					let pixel_x = (tile_index % tile_width) * BOUND + x;
					if(pixel_x >= image_width){
						continue
					}
					entropyData[pixel_y][pixel_x] = local_estimateEntropy_exclusive(global_table,[group[gIndex++]])
				}
			}
		});
		let imagedata2 = green_channel.flat();
		let entropyData2 = entropyData.flat();
		let wiki2 = new Array(image_height).fill(0).map(_ => new Array(image_width).fill(0));
		let matchDistances = [];
		let matchLengths = [];
		let nextDistances = [];
		let savedEnt = 0;
		let previousSeen = -1;
		for(let i=0;i<imagedata2.length;i++){
			let bestMatch = 0;
			let bestLength = 0;
			let bestMatch_ent = 0;
			let bestMatch_ent_comp = 0;
			for(let j=1;j<lzrangeormixfree && i - j > 0;j++){
				let l_ent = 0;
				for(let k=1;k<maxmatch && (i + k - 1) < imagedata2.length;k++){
					if(imagedata2[i] !== imagedata2[i - j + k - 1]){
						if(k >= minmatch && ((l_ent - codeFromValue(j)[1] - codeFromValue(k)[1]) > bestMatch_ent_comp)){
							bestMatch = j;
							bestMatch_ent = l_ent;
							bestMatch_ent_comp = l_ent - codeFromValue(j)[1] - codeFromValue(k)[1];
							bestLength = k;
						}
						break
					}
					l_ent += entropyData2[i + k - 1]
				}
			}
			if(bestMatch && bestMatch_ent >= minentropy){
				matchDistances.push(bestMatch);
				matchLengths.push(bestLength);
				savedEnt += bestMatch_ent;
				nextDistances.push(i - previousSeen);
				for(let retrace=0;retrace < bestLength;retrace++){
					try{
						wiki2[Math.floor(i / image_width)][i % image_width] = 255;
					}
					catch(e){
						console.log(i,Math.floor(i / image_width),image_height)
					}
					i++
				}
				i--;
				previousSeen = i;
			}
		}
		drawCost(wiki2,image_width,image_height);
		let c_1 = estimateEntropy_prefixcode(matchDistances)/8;
		let c_2 = estimateEntropy_prefixcode(matchLengths)/8
		let c_3 = estimateEntropy_prefixcode(nextDistances)/8
		console.log("mDist",matchDistances,c_1);
		console.log("mLength",matchLengths,c_2);
		console.log("mNext",nextDistances,c_3);
		console.log("saved",savedEnt/8);
		console.log("total",savedEnt/8 - c_1 - c_2 - c_3,entropyData2.reduce((acc,val) => acc + val,0)/8 - (savedEnt/8 - c_1 - c_2 - c_3));
	}
	else if(lzrangeormixfree === "mixfree"){
		let heatMap = coded.map(misses => local_estimateEntropy_exclusive(global_table,misses));
		let medianSplitter = Stats.median(heatMap);
		let groups = [[],[]];
		coded.forEach((cell,index) => {
			if(heatMap[index] < medianSplitter){
				groups[0].push(cell)
			}
			else{
				groups[1].push(cell)
			}
		});
		let entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
		console.log((entropy)/8,"secondary",groups.map(val => val.length));
		console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)))/8,"implied overhead + " + groups.length + " frequency tables");

		let frequencies = groups.map(group => freqs(group.flat()));

		let coded2;
		let predictorCounts;

		for(let iterations=0;iterations < contexts + 3;iterations++){
			iterations++;
			let new_tiles = [];
			tile_predictors.forEach((tile,index) => {
				let predictor_results = groups.map((group,gIndex) =>
					predictors.map((predictor,pIndex) => 
						local_estimateEntropy_inclusive(
							frequencies[gIndex],
							predictBlock(pIndex,index)
						)
					).concat(
						mixers.map((_,mIndex) =>
							local_estimateEntropy_inclusive(
								frequencies[gIndex],
								predictBlockMix2(index,mIndex)
							)
						)
					)
				)
				let bests = predictor_results.map(result => Math.min(...result));
				let best_best = Math.min(...bests);
				let best_best_index = bests.indexOf(best_best);
				new_tiles.push(predictor_results[best_best_index].indexOf(best_best))
			});

			coded2 = new_tiles.map((predictor,index) => 
				(predictor >= predictors.length ? predictBlockMix2(index,predictor - predictors.length) : predictBlock(predictor,index))
			);

			groups = groups.map(_ => []);
			coded2.forEach((cell,index) => {
				let estimates = frequencies.map(frequency => local_estimateEntropy_inclusive(frequency,cell));
				groups[estimates.indexOf(Math.min(...estimates))].push(cell)
			});
			groups = groups.filter(group => group.length);

			frequencies = groups.map(group => freqs(group.flat()));
			if(groups.length < contexts){
				let lengths = groups.map(a => a.length);

				let largestIndex = lengths.indexOf(Math.max(...lengths));
				let largest = groups.splice(largestIndex,1)[0];

				heatMap = largest.map(misses => local_estimateEntropy_exclusive(frequencies[largestIndex],misses));
				medianSplitter = Stats.median(heatMap);
				let group_lower = [];
				let group_upper = [];
				largest.forEach((cell,index) => {
					if(heatMap[index] < medianSplitter){
						group_lower.push(cell)
					}
					else{
						group_upper.push(cell)
					}
				});

				if(group_lower.length){
					groups.push(group_lower)
				}
				if(group_upper.length){
					groups.push(group_upper)
				}
				frequencies = groups.map(group => freqs(group.flat()));
			}

			entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
			tile_predictors = new_tiles;
			predictorCounts = new Array(predictors.length + mixers.length).fill(0);
			tile_predictors.forEach(predictor => {
				predictorCounts[predictor]++
			})
			console.log(entropy/8,"secondary with search",groups.map(val => val.length));
			console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)) + estimateEntropy_freqs(predictorCounts))/8,"implied overhead + " + groups.length + " frequency tables");
		}
		for(let i=0;i<5;i++){
			groups = groups.map(_ => []);
			coded2.forEach((cell,index) => {
				let estimates = frequencies.map(frequency => local_estimateEntropy_inclusive(frequency,cell));
				let group_index = estimates.indexOf(Math.min(...estimates));
				tile_entropy[index] = group_index;
				groups[group_index].push(cell)
			});
			groups = groups.filter(group => group.length);

			frequencies = groups.map(group => freqs(group.flat()));
			entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
			console.log(entropy/8,"secondary, adjustment" + 1,groups.map(val => val.length));
			console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)) + estimateEntropy_freqs(predictorCounts))/8,"implied overhead + " + groups.length + " frequency tables");
		}
		let predMap_cost = Math.ceil(estimateEntropy_freqs(predictorCounts)/8);
		let entrMap_cost = Math.ceil(estimateEntropy_freqs(groups.map(group => group.length))/8);
		let table_cost = frequencies.reduce((acc,val) => acc + estimate_table_size(val),0);
		console.log("overhead",predMap_cost,entrMap_cost,table_cost);
		console.log("total",Math.ceil(entropy/8 + predMap_cost + entrMap_cost + table_cost));
		console.log("predictors",predictorCounts.map((count,index) => count + " " + (predictors[index] || {name: "mixer"}).name));
		drawEntropyMap(tile_entropy.map(val => Math.floor(255 * val/(groups.length - 1))),tile_width,tile_height)
		drawPredictorMap(tile_predictors.map(val => Math.floor(255 * val/(predictors.length + mixers.length - 1))),tile_width,tile_height)
	}
	else if(contexts === 1){
		for(let i=0;i<3;i++){
			let new_tiles = [];
			tile_predictors.forEach((tile,index) => {
				let predictor_results = predictors.map((predictor,pIndex) => 
					local_estimateEntropy_inclusive(
						global_table,
						predictBlock(pIndex,index)
					)
				);
				predictor_results.push(
					local_estimateEntropy_inclusive(
						global_table,
						predictBlockMix(index)
					)
				)
				new_tiles.push(predictor_results.indexOf(Math.min(...predictor_results)))
			});
			let coded2 = new_tiles.map((predictor,index) => (predictor === predictors.length ? predictBlockMix(index) : predictBlock(predictor,index)));
			let entropy2 = estimateEntropy(coded2.flat());
			if(entropy2 > entropy){
				break
			}
			entropy = entropy2;
			tile_predictors = new_tiles;
			global_table = freqs(coded2.flat());
			global_coded = coded2.flat();
			console.log(entropy/8,"secondary");
		}
		let predictorCounts = new Array(predictors.length + 1).fill(0);
		tile_predictors.forEach(predictor => {
			predictorCounts[predictor]++
		});
		let predMap_cost = Math.ceil(estimateEntropy_freqs(predictorCounts)/8);
		let table_cost = estimate_table_size(global_table);
		console.log("global",global_table.join(","));
		console.log("overhead",predMap_cost,table_cost);
		console.log("predictors",predictorCounts);
		console.log("total",Math.ceil(predMap_cost + table_cost + entropy/8));
	}
/*
	else if(contexts === 2){
		let heatMap = coded.map(misses => local_estimateEntropy_exclusive(global_table,misses));
		let medianSplitter = Stats.median(heatMap);
		let group_lower = [];
		let group_upper = [];
		coded.forEach((cell,index) => {
			if(heatMap[index] < medianSplitter){
				group_lower.push(cell)
			}
			else{
				group_upper.push(cell)
			}
		});
		let entropy_lower = estimateEntropy(group_lower.flat());
		let entropy_upper = estimateEntropy(group_upper.flat());
		console.log((entropy_lower + entropy_upper)/8,"secondary",group_lower.length,group_upper.length);
		console.log((tile_number * 1/3 + estimateEntropy_freqs([group_lower.length,group_upper.length]))/8,"implied overhead + 2 frequency tables");

		let lower_freqs;
		let upper_freqs;
		for(let i=0;i<5;i++){
			lower_freqs = freqs(group_lower.flat());
			upper_freqs = freqs(group_upper.flat());
			group_lower = [];
			group_upper = [];
			coded.forEach((cell,index) => {
				let if_lower = local_estimateEntropy_inclusive(lower_freqs,cell);
				let if_upper = local_estimateEntropy_inclusive(upper_freqs,cell);
				if(if_lower < if_upper){
					group_lower.push(cell)
				}
				else{
					group_upper.push(cell)
				}
			});
			entropy_lower = estimateEntropy(group_lower.flat());
			entropy_upper = estimateEntropy(group_upper.flat());
			console.log((entropy_lower + entropy_upper)/8,"secondary adjusted " + i,group_lower.length,group_upper.length);
		}
		console.log((tile_number * 1/3 + estimateEntropy_freqs([group_lower.length,group_upper.length]))/8,"implied overhead + 2 frequency tables");

		//predictor search
		for(let i=0;i<3;i++){
			let new_tiles = [];
			tile_predictors.forEach((tile,index) => {
				let predictor_results_lower = predictors.map((predictor,pIndex) => 
					local_estimateEntropy_inclusive(
						lower_freqs,
						predictBlock(pIndex,index)
					)
				);
				let predictor_results_upper = predictors.map((predictor,pIndex) => 
					local_estimateEntropy_inclusive(
						upper_freqs,
						predictBlock(pIndex,index)
					)
				);
				let lower_best = Math.min(...predictor_results_lower);
				let upper_best = Math.min(...predictor_results_upper);
				if(lower_best < upper_best){
					new_tiles.push(predictor_results_lower.indexOf(lower_best))
				}
				else{
					new_tiles.push(predictor_results_upper.indexOf(upper_best))
				}
			});

			let coded2 = new_tiles.map((predictor,index) => predictBlock(predictor,index));

			group_lower = [];
			group_upper = [];
			coded2.forEach((cell,index) => {
				let if_lower = local_estimateEntropy_inclusive(lower_freqs,cell);
				let if_upper = local_estimateEntropy_inclusive(upper_freqs,cell);
				if(if_lower < if_upper){
					group_lower.push(cell);
					tile_entropy[index] = 1
				}
				else{
					group_upper.push(cell);
					tile_entropy[index] = 0
				}
			});
			entropy_lower = estimateEntropy(group_lower.flat());
			entropy_upper = estimateEntropy(group_upper.flat());

			let entropy2 = entropy_lower + entropy_upper;
			if(entropy2 > entropy){
				break
			}
			entropy = entropy2;
			tile_predictors = new_tiles;
			lower_freqs = freqs(group_lower.flat());
			upper_freqs = freqs(group_upper.flat());
			console.log(entropy/8,"secondary with search " + i,group_lower.length,group_upper.length);
		}
		let predictorCounts = new Array(predictors.length).fill(0);
		tile_predictors.forEach(predictor => {
			predictorCounts[predictor]++
		})
		let predMap_cost = Math.ceil(estimateEntropy_freqs(predictorCounts)/8);
		let entrMap_cost = Math.ceil(estimateEntropy_freqs([group_lower.length,group_upper.length])/8);
		let table_cost = estimate_table_size(lower_freqs) + estimate_table_size(upper_freqs);
		console.log("overhead",predMap_cost,entrMap_cost,table_cost);
		console.log("total",Math.ceil(entropy/8 + predMap_cost + entrMap_cost + table_cost));
		drawEntropyMap(tile_entropy.map(val => Math.floor(255 * val)),tile_width,tile_height)
		drawPredictorMap(tile_predictors.map(val => Math.floor(255 * val/(predictors.length - 1))),tile_width,tile_height)
	}
*/
	else{
		let heatMap = coded.map(misses => local_estimateEntropy_exclusive(global_table,misses));
		let medianSplitter = Stats.median(heatMap);
		let groups = [[],[]];
		coded.forEach((cell,index) => {
			if(heatMap[index] < medianSplitter){
				groups[0].push(cell)
			}
			else{
				groups[1].push(cell)
			}
		});
		let entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
		console.log((entropy)/8,"secondary",groups.map(val => val.length));
		console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)))/8,"implied overhead + " + groups.length + " frequency tables");

		let frequencies = groups.map(group => freqs(group.flat()));

		let coded2;
		let predictorCounts;

		for(let iterations=0;iterations < contexts + 3;iterations++){
			iterations++;
			let new_tiles = [];
			tile_predictors.forEach((tile,index) => {
				let predictor_results = groups.map((group,gIndex) =>
					predictors.map((predictor,pIndex) => 
						local_estimateEntropy_inclusive(
							frequencies[gIndex],
							predictBlock(pIndex,index)
						)
					).concat(
						local_estimateEntropy_inclusive(
							frequencies[gIndex],
							predictBlockMix(index)
						)
					)
				);
				let bests = predictor_results.map(result => Math.min(...result));
				let best_best = Math.min(...bests);
				let best_best_index = bests.indexOf(best_best);
				new_tiles.push(predictor_results[best_best_index].indexOf(best_best))
			});

			coded2 = new_tiles.map((predictor,index) => (predictor === predictors.length ? predictBlockMix(index) : predictBlock(predictor,index)));

			groups = groups.map(_ => []);
			coded2.forEach((cell,index) => {
				let estimates = frequencies.map(frequency => local_estimateEntropy_inclusive(frequency,cell));
				groups[estimates.indexOf(Math.min(...estimates))].push(cell)
			});
			groups = groups.filter(group => group.length);

			frequencies = groups.map(group => freqs(group.flat()));
			if(groups.length < contexts){
				let lengths = groups.map(a => a.length);

				let largestIndex = lengths.indexOf(Math.max(...lengths));
				let largest = groups.splice(largestIndex,1)[0];

				heatMap = largest.map(misses => local_estimateEntropy_exclusive(frequencies[largestIndex],misses));
				medianSplitter = Stats.median(heatMap);
				let group_lower = [];
				let group_upper = [];
				largest.forEach((cell,index) => {
					if(heatMap[index] < medianSplitter){
						group_lower.push(cell)
					}
					else{
						group_upper.push(cell)
					}
				});

				if(group_lower.length){
					groups.push(group_lower)
				}
				if(group_upper.length){
					groups.push(group_upper)
				}
				frequencies = groups.map(group => freqs(group.flat()));
			}

			entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
			tile_predictors = new_tiles;
			predictorCounts = new Array(predictors.length + 1).fill(0);
			tile_predictors.forEach(predictor => {
				predictorCounts[predictor]++
			})
			console.log(entropy/8,"secondary with search",groups.map(val => val.length));
			console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)) + estimateEntropy_freqs(predictorCounts))/8,"implied overhead + " + groups.length + " frequency tables");
		}
		for(let i=0;i<5;i++){
			groups = groups.map(_ => []);
			coded2.forEach((cell,index) => {
				let estimates = frequencies.map(frequency => local_estimateEntropy_inclusive(frequency,cell));
				let group_index = estimates.indexOf(Math.min(...estimates));
				tile_entropy[index] = group_index;
				groups[group_index].push(cell)
			});
			groups = groups.filter(group => group.length);

			frequencies = groups.map(group => freqs(group.flat()));
			entropy = groups.reduce((acc,val) => acc + estimateEntropy(val.flat()),0);
			console.log(entropy/8,"secondary, adjustment" + 1,groups.map(val => val.length));
			console.log((tile_number * 1/3 + estimateEntropy_freqs(groups.map(val => val.length)) + estimateEntropy_freqs(predictorCounts))/8,"implied overhead + " + groups.length + " frequency tables");
		}
		let predMap_cost = Math.ceil(estimateEntropy_freqs(predictorCounts)/8);
		let entrMap_cost = Math.ceil(estimateEntropy_freqs(groups.map(group => group.length))/8);
		let table_cost = frequencies.reduce((acc,val) => acc + estimate_table_size(val),0);
		console.log("overhead",predMap_cost,entrMap_cost,table_cost);
		console.log("total",Math.ceil(entropy/8 + predMap_cost + entrMap_cost + table_cost));
		console.log("predictors",predictorCounts);
		drawEntropyMap(tile_entropy.map(val => Math.floor(255 * val/(groups.length - 1))),tile_width,tile_height)
		drawPredictorMap(tile_predictors.map(val => Math.floor(255 * val/(predictors.length))),tile_width,tile_height)
	}
}


const inputElementEncode = document.getElementById("imageInput");
const buttonElementEncode = document.getElementById("encodeButton");

let html_encode = function(){
	if(inputElementEncode.files && inputElementEncode.files[0]){
		let fileName = inputElementEncode.files[0].name;
		let FR = new FileReader();
		FR.onload = function(e){
			let img = new Image();
			img.addEventListener("load", function(){
				let canvas = document.getElementById("preview");
				canvas.height = img.height;
				canvas.width = img.width;
				let ctx = canvas.getContext("2d");
				ctx.drawImage(img, 0, 0);
				let contextData = ctx.getImageData(0,0,img.width,img.height).data;

				let sub_green_data = rgba_to_subgreena(contextData);
				green_channel = deMultiplexChannels(sub_green_data,img.width,img.height)[0];
				drawGreyscale(green_channel,img.width,img.height);
			});
			img.src = e.target.result;
		};
		FR.readAsDataURL(inputElementEncode.files[0]);
	}
}
inputElementEncode.addEventListener("change",html_encode,false);
buttonElementEncode.addEventListener("click",html_encode,false);
		</script>
	</body>
</html>
